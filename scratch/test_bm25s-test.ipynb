{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "import Stemmer  # optional: for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your corpus here\n",
    "corpus = [\n",
    "    \"a cat is a feline and likes to purr\",\n",
    "    \"a dog is the human's best friend and loves to play\",\n",
    "    \"a bird is a beautiful animal that can fly\",\n",
    "    \"a fish is a creature that lives in water and swims\",\n",
    "]\n",
    "\n",
    "# optional: create a stemmer\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the corpus\n",
    "query = \"Does the FISH purr like a cat?\"\n",
    "query_tokens = bm25s.tokenize(query, stemmer=stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results, scores = retriever.retrieve(query_tokens, corpus=corpus, k=2)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the arrays to a directory...\n",
    "retriever.save(\"animal_index_bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the corpus along with the model\n",
    "retriever.save(\"animal_index_bm25_model\", corpus=corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and load them when you need them\n",
    "import bm25s\n",
    "reloaded_retriever = bm25s.BM25.load(\"animal_index_bm25\", load_corpus=True)\n",
    "# set load_corpus=False if you don't need the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the corpus\n",
    "query2 = \"Why is my bird so noisy?\"\n",
    "query2_tokens = bm25s.tokenize(query2, stemmer=stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results2, scores2 = reloaded_retriever.retrieve(query2_tokens, corpus=corpus, k=2)\n",
    "\n",
    "for i in range(results2.shape[1]):\n",
    "    doc, score = results2[0, i], scores2[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import bm25s\n",
    "import Stemmer \n",
    "stemmer = Stemmer.Stemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Index the vault \n",
    "\n",
    "# specify the vault name to separate the indexes\n",
    "vault_name = \"testvault\"\n",
    "\n",
    "# get vault documents via API from user as a list  [vault_name, vault_documents (dict of file_name and file_content)]\n",
    "# convert dict element vault_documents to two lists: file_names and file_contents\n",
    "\n",
    "# this is temporary to read from local directory\n",
    "import os\n",
    "def load_files_from_directory(directory):\n",
    "    file_names = []\n",
    "    file_contents = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    file_names.append(file)\n",
    "                    file_contents.append(f.read())\n",
    "    return file_names, file_contents\n",
    "\n",
    "file_names, file_contents = load_files_from_directory('./data/sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "import re\n",
    "\n",
    "character_patterns = {\n",
    "    \"bold\": r\"\\*\\*(.*?)\\*\\*|__(.*?)__\",  # Removes ** and __ while keeping the text\n",
    "    \"italic\": r\"\\*(.*?)\\*|_(.*?)_\",  # Removes * and _ while keeping the text\n",
    "    \"inline_code\": r\"`(.*?)`\",  # Removes ` while keeping the inline code text\n",
    "    \"links\": r\"$begin:math:display$(.*?)$end:math:display$$begin:math:text$.*?$end:math:text$\",  # Removes the link notation, keeping the link text only\n",
    "    \"images\": r\"!$begin:math:display$.*?$end:math:display$$begin:math:text$.*?$end:math:text$\",  # Removes the entire image markdown, as it typically doesn't have useful visible text\n",
    "    \"headings\": r\"^#+\\s*(.*?)$\",  # Removes the # characters while keeping the heading text\n",
    "    \"blockquotes\": r\"^>\\s*(.*?)$\",  # Removes the > character while keeping the quoted text\n",
    "    \"code_blocks\": r\"```(?:.|\\n)*?```\",  # Removes fenced code block notation while keeping the code\n",
    "    \"list_items\": r\"^[-*]\\s+\",  # Removes list markers (- or *) while keeping the list item text\n",
    "    \"extra_newlines\": r\"\\n{2,}\",  # Collapses multiple newlines into one\n",
    "    \"unicode escapes\": r\"(\\\\u[0-9a-fA-F]{4})+\", \n",
    "    \"outbound links\": r\"https?://\\S+\",\n",
    "    \"image linkes\": r\"!\\[\\[.*?\\]\\]|\\!\\[.*?\\]\\(.*?\\)\"\n",
    "}\n",
    "\n",
    "for key, value in character_patterns.items():\n",
    "    file_contents = [re.sub(value, '', file) for file in file_contents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3a0d14506145e1aee2b4851a1bafc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a09d38abab34368a07023ce6fbd9282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e026cb0e17b44cad9f8443c4cadadbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce48842655c4cb99962674c8baf3998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14f6988440046fb8cf339075d017489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding newlines for mmindex:   0%|          | 0.00/23.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the corpus and only keep the ids\n",
    "corpus_tokens = bm25s.tokenize(file_contents, stopwords=\"en\", stemmer=stemmer)\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "# Save model and file names \n",
    "retriever.save(f\"./vault_indexes/{vault_name}_index/\", corpus=file_names)\n",
    "\n",
    "# send message to user that indexing is complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1966944ca3f94713b1dffbe6a4467dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab4a03ace294584910604ddb90f80c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8551f5a3a21d4fc49f17b9fe0f056c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Query the vault index\n",
    "\n",
    "# get query via API from user as a list [vault_name (string), query (string)]\n",
    "\n",
    "# this is temporary \n",
    "vault_name = \"testvault\"\n",
    "query = \"software development\"\n",
    "\n",
    "# tokenize query\n",
    "query_tokens = bm25s.tokenize(query, stemmer=stemmer)\n",
    "\n",
    "# load the model \n",
    "retriever = bm25s.BM25.load(f\"./vault_indexes/{vault_name}_index/\", load_corpus=True)\n",
    "\n",
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results, scores = retriever.retrieve(query_tokens, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return object with file names and scores in order\n",
    "final_results = []\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    final_results.append({'doc':doc['text'], 'score':round(float(score), 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc': 'LLM Observability & Evaluation.md', 'score': 2.65},\n",
       " {'doc': 'Beyond the Imitation Game (BIG-Bench).md', 'score': 2.33},\n",
       " {'doc': 'Agile + Scrum.md', 'score': 2.32},\n",
       " {'doc': 'Some High-Tech Career Counseling Tips.md', 'score': 1.91},\n",
       " {'doc': 'SuperGLUE.md', 'score': 1.88},\n",
       " {'doc': 'CUNY DATA 607 Week 7 Assignment.md', 'score': 1.85},\n",
       " {'doc': 'Challenges in Evaluating AI systems.md', 'score': 1.51},\n",
       " {'doc': 'AI Index Report 2024 – Artificial Intelligence Index.md',\n",
       "  'score': 1.43},\n",
       " {'doc': 'Assumptions.md', 'score': 1.39},\n",
       " {'doc': 'W3 - Growth Models.md', 'score': 1.39}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
